# model_module.py

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

class NeuralNetworkModel:
    def __init__(self, input_dim, learning_rate=0.001):
        """
        Initializes the neural network model.

        Parameters:
        - input_dim (int): Number of input features.
        - learning_rate (float): Learning rate for the Adam optimizer.
        """
        self.model = Sequential([
            Dense(64, input_dim=input_dim, activation='relu'),
            Dense(32, activation='relu'),
            Dense(1)  # Output layer for regression
        ])
        self.model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))
    
    def train(self, X_train, y_train, X_val, y_val, epochs=20, batch_size=10):
        """
        Trains the model.

        Parameters:
        - X_train, y_train: Training data and labels.
        - X_val, y_val: Validation data and labels.
        - epochs (int): Number of epochs for training.
        - batch_size (int): Batch size for training.

        Returns:
        - history: Training history object.
        """
        return self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))
    
    def evaluate(self, X_test, y_test):
        """
        Evaluates the model on the test data.

        Parameters:
        - X_test, y_test: Test data and labels.

        Returns:
        - test_loss: Test loss (mean squared error).
        """
        test_loss = self.model.evaluate(X_test, y_test)
        print(f"Test Loss (Mean Squared Error): {test_loss}")
        return test_loss
